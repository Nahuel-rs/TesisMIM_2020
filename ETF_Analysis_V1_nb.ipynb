## IMPORTING LIBRARIES

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import math
import yfinance as yf
import statistics as st
import os
import time
from pandas_datareader import data as pdr
from statsmodels.tsa.arima_model import ARIMA
from sklearn.metrics import mean_squared_error
from tqdm import tqdm, tqdm_notebook
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier
from sklearn.metrics import roc_curve, classification_report, confusion_matrix,ConfusionMatrixDisplay, f1_score

import YC_Analysis_V3

## FUNCTIONS

# Sample the information into volume bars. Technique replicated from Lopez de Prado.
def filter_volume_bars(df, volume_column, m):
    t = df[volume_column]
    ts = 0
    idx = []
    for i, x in enumerate(tqdm(t)):
        ts += x
        if ts >= m:
            idx.append(i)
            ts = 0
            continue
    return idx

def filter_volume_bar_df(df, volume_column, m):
    idx = filter_volume_bars(df, volume_column, m)
    return df.iloc[idx].drop_duplicates()

# Defines a meta_label to represent if the signal was correct. (e.g. if the label was 1 (long), price raised on the next bar)
def meta_labeling(df,signal_column):
    new_df = df.copy()
    new_df = new_df.reset_index()
    new_df['Meta_Label'] = ''
    new_df = new_df.astype({'Signal':'int64'})
    for i in new_df.index:
        if i == new_df.index[-1]:
            break;        
        if new_df.loc[i,signal_column] == 1: #Long Signal
            if new_df.loc[i,'Close'] <= new_df.loc[i+1,'Close']:
                new_df.loc[i,'Meta_Label'] = 1 #Next price is higher or same, take the bet.
            else:
                new_df.loc[i,'Meta_Label'] = 0 #Next price is lower, do not take the bet.
                
        elif new_df.loc[i,:][signal_column] == -1: #Short Signal
            if new_df.loc[i,'Close'] < new_df.loc[i+1,'Close']:
                new_df.loc[i,'Meta_Label'] = 0 #Next price is higher, do not take the bet.
            else:
                new_df.loc[i,'Meta_Label'] = 1 #Next price is lower or same, take the bet.    
    new_df = new_df.set_index('Date')
    return new_df

def plot_volume_and_price(df):
    fig, ax1 = plt.subplots()
    ax1.plot(df['Close'], 'b-')
    ax1.set_ylabel('Close Price', color='b')
    [tl.set_color('b') for tl in ax1.get_yticklabels()]
    ax2 = ax1.twinx()
    ax2.bar(df.index,df['Volume'])
    ax2.set_xlabel('Date')
    ax2.set_ylabel('Volume', color='g')
    [tl.set_color('g') for tl in ax2.get_yticklabels()]
    plt.show()
    
def plot_signal_proportion(x,y):
    objects = x
    y_pos = np.arange(len(objects))
    performance = []
    for i in y:
        performance.append(round(i*100,2))
    
    plt.bar(y_pos, performance, align='center', alpha=0.5)
    plt.xticks(y_pos, objects)
    plt.ylabel('Percentage')
    plt.title('Meta-Label distribution')
    plt.ylim(0, 100)
    
    for index,data in enumerate(performance):
        print(index,data)
        plt.text(x=index-0.1 , y =data+1 , s=f"{data}%" , fontdict=dict(fontsize=12))
    
    plt.show()


def return_weight(df,price_column):
    returns = []
    price_array = list(df[price_column])
    for i in range(len(price_array)):
        if i != (len(price_array)-1):
            returns.append(abs(price_array[i+1]-price_array[i]))
    weights = []
    max_return = max(returns)
    for i in range(len(returns)):
        weights.append(returns[i]/max_return)
    return weights

def getTimeDecay(tW,clfLastW=1.):
    # apply piecewise-linear decay to observed uniqueness (tW)
    # newest observation gets weight=1, oldest observation gets weight=clfLastW
    clfW=tW.sort_index().cumsum()
    if clfLastW>=0:slope=(1.-clfLastW)/clfW.iloc[-1]
    else:slope=1./((clfLastW+1)*clfW.iloc[-1])
    const=1.-slope*clfW.iloc[-1]
    clfW=const+slope*clfW
    clfW[clfW<0]=0
    return clfW

def final_weight(df,price_column,factor):
    return_weights = return_weight(df,price_column)
    time_weights = list(getTimeDecay(df[price_column], clfLastW=factor))[:-1]
    model_weight = []
    for i in range(len(return_weights)):
        model_weight.append(return_weights[i]*time_weights[i])
    max_w = max(model_weight)
    final_weights = []
    for i in range(len(model_weight)):
        final_weights.append(model_weight[i]/max_w)            
    return final_weights
        
def ROC_Curve(fpr,tpr):
    plt.plot([0, 1], [0, 1], 'k--')
    plt.plot(fpr, tpr, label='RF')
    plt.xlabel('False positive rate')
    plt.ylabel('True positive rate')
    plt.title('ROC curve')
    plt.legend(loc='best')
    plt.show()  

def Conf_Matrix(y_test,y_pred):
    conf_mat = confusion_matrix(y_test, y_pred)
    plt.matshow(conf_mat, cmap='jet')
    for (i, j), z in np.ndenumerate(conf_mat):
        plt.text(j, i, '{:0.1f}'.format(z), ha='center', va='center')   
    plt.title("Confusion matrix")
    plt.colorbar()

def generate_k_folds_with_embargo(df,n_folds):
    main_index = df.index
    result_folds = pd.DataFrame(columns=['fold','tr_index','vl_index'])
    p = 1.0 / n_folds
    for fold in range(n_folds):
        
        if fold == 0:
            vl_start = 0
            vl_end = int(p*len(main_index))
            vl_index = main_index[vl_start:vl_end]
            tr_index = df.loc[~df.index.isin(vl_index)].index
            tr_index = tr_index[5:] # Apply Embargo, only to the final of the dataset.
            
        elif fold == n_folds-1:
            vl_start = int((p*fold)*len(main_index))
            vl_end = int(len(main_index))
            vl_index = main_index[vl_start:vl_end]
            tr_index = df.loc[~df.index.isin(vl_index)].index
            # Embargo not required, not seeing future information.
            
        else:
            vl_start = int((p*fold)*len(main_index))
            vl_end = int((p*(fold+1))*len(main_index))
            vl_index = main_index[vl_start:vl_end]
            tr_index = df.loc[~df.index.isin(vl_index)].index
            tr_index = tr_index[5:] # Apply Embargo to the start of the dataset.
            tr_index = tr_index[:-5] # Apply Embargo to the final of the dataset.
            
        result_folds = result_folds.append({'fold':fold,'tr_index':tr_index,'vl_index':vl_index},ignore_index=True)
        
    result_folds = result_folds.set_index('fold',drop=True)
    return result_folds
        

def evaluate_best_parameters_rf(df,n_folds, n_est,m_dep,min_s_spl,min_s_l,max_f,min_i,min_w):
    fold_df = generate_k_folds_with_embargo(df,n_folds)
    possibilities = len(n_est)*len(m_dep)*len(min_s_spl)*len(min_s_l)*len(max_f)*len(min_i)*len(min_w)
    s = time.time()
    
    evaluation_results = pd.DataFrame(columns=['n_est','max_depth','min_samples_split','min_samples_leaf',
                                               'max_features','min_impurity_d','min_weight_fractleaf','F1_Score'])
    
    for a in n_est:
        for b in m_dep:
            for c in min_s_spl:
                for d in min_s_l:
                    for e in max_f:
                        for f in min_i:
                            for g in min_w:
                                f1_collection = []
                                for fold in range(n_folds):
                                    model=RandomForestClassifier(
                                    n_estimators=a,
                                    max_depth=b,
                                    min_samples_split=c,
                                    min_samples_leaf=d,
                                    max_features=e,
                                    min_impurity_decrease=f,
                                    min_weight_fraction_leaf=g)
                                    
                                    df_test = df.loc[df.index.isin(fold_df.loc[fold,'vl_index'])]
                                    y_test = df_test.iloc[:,-1]
                                    x_test = df_test.iloc[:,:-1]
                                    
                                    df_train = df.loc[df.index.isin(fold_df.loc[fold,'tr_index'])]
                                    y_train = df_train.iloc[:,-1]
                                    x_train = df_train.iloc[:,:-1]
                                    
                                    model_weights = final_weight(x_train,'Close',0.25)
                                    
                                    x_train = x_train.iloc[:-1]
                                    y_train = y_train.iloc[:-1]
                                    
                                    rf = model.fit(x_train, y_train, sample_weight=model_weights)
                                    
                                    y_pred = rf.predict(x_test)
                                    print('f1_score:',f1_score(y_test, y_pred, average='micro'))
                                    f1_collection.append(f1_score(y_test, y_pred, average='micro'))
                                evaluation_results = evaluation_results.append({'n_est':a,'max_depth':b,'min_samples_split':c,
                                                                                'min_samples_leaf':d,'max_features':e,
                                                                                'min_impurity_d':f,'min_weight_fractleaf':g,
                                                                                'F1_Score':st.mean(f1_collection)},ignore_index=True)
    print('Time elapsed: {} for {} combinations'.format(round((time.time()-s)/60,2),possibilities))                            
    return evaluation_results

def normalize_prob(input_series):
    prob_series  = input_series.copy()
    max_value = max(prob_series)
    for i in range(len(prob_series)):
        prob_series[i] = prob_series[i]/max_value
    return prob_series   

                                
def back_test(df,mode, risk_free = 0.0):
    # df1 = df.loc[start_date:end_date]
    df1 = df
    ''' Modos disponibles:
        1- 'Simple' -> Simple: Toma la performance de una estrategia "Buy and Hold". Compra en t=1, vende en t=T (Ultimo dia)
        2- 'Signal' -> Señal: Compra y vende segun el campo 'Buy/Sell'. Size es 1 siempre.
        3- 'BetS' -> Bet Sizing: Usa la señal del campo Buy/Sell y la pondera por la probabilizada del campo 'BetSize'. '''
        
    if mode == 'Simple':
        print('Modo Simple!')
        opening_price = df1['Close'].first('D')[0]
        closing_price = df1['Close'].last('D')[0]
        result = (closing_price - opening_price) / opening_price
        # print('Opening Price: $ {:.2f}'.format(opening_price))
        # print('Closing Price: $ {:.2f}'.format(closing_price))
        print('Rate of Return: {:.2%}'.format(result))
        trades = pd.DataFrame()
        return result
        
    elif mode == 'Signal':
        print('Modo via señales!')
        trades = pd.DataFrame(columns=['Opening_Price','Closing_Price','Return','Type'])
        position = 0
        trade_count = 0
        long_count = 0
        for i in df1.index:
            if position == 0:
                position = df1.loc[i,'Buy_or_Sell']
                open_price = df1.loc[i,'Close']
            elif position == 1 and (df1.loc[i,'Buy_or_Sell'] == -1 or i == (len(df1)-1)):
                # Cambio de Buy a Sell
                result = (df1.loc[i,'Close'] - open_price) / open_price
                trades = trades.append({'Opening_Price':open_price,'Closing_Price':df1.loc[i,'Close'],'Return':result,'Type':'Long'}, ignore_index=True)
                open_price = df1.loc[i,'Close']
                trade_count += 1
                long_count += 1
                
            elif position == -1 and (df1.loc[i,'Buy_or_Sell'] == 1 or i == (len(df1)-1)):
                # Cambio de Sell a Buy
                result = (open_price - df1.loc[i,'Close']) / open_price
                trades = trades.append({'Opening_Price':open_price,'Closing_Price':df1.loc[i,'Close'],'Return':result,'Type':'Short'}, ignore_index=True)
                open_price = df1.loc[i,'Close']
                trade_count += 1
                
            position = df1.loc[i,'Buy_or_Sell']
        
        # print('*********** Trades ejecutados: **************')
        # print('*********************************************')
        # for i in range(len(trades)):
        #     print('Trade {}, tipo: {}'.format(i,trades.iloc[i,3]))
        #     print('Abrio al precio de $ {:.2f} y cerro en $ {:.2f}'.format(trades.iloc[i,0],trades.iloc[i,1]))
        #     print('Retorno: {:.2%}'.format(trades.iloc[i,2]))
        #     print('*********************************************')
        
        print('Portfolio result: {:.2%}'.format(trades['Return'].sum()))
        print('Trade quantity: {}'.format(trade_count))
        print('Ratio of Longs: {:.2%}'.format(long_count/trade_count))
        print('Sharpe Ratio: {:.3f}'.format((trades['Return'].sum()-risk_free)/trades['Return'].std()))
        print(trades['Return'].sum(),trades['Return'].std())
        return (trades['Return'].sum(),((trades['Return'].sum()-risk_free)/trades['Return'].std()))
                                                 
    elif mode == 'BetS':
        print('Modo via señales y bet sizing!')
        trades = pd.DataFrame(columns=['Opening_Price','Closing_Price','Return','Type','Bet Size'])
        position = 0
        trade_count = 0
        long_count = 0
        for i in df1.index:
            if position == 0:
                position = df1.loc[i,'Buy_or_Sell']
                open_price = df1.loc[i,'Close']
                bet_size = df1.loc[i,'Bet_Size']
            elif position == 1 and (df1.loc[i,'Buy_or_Sell'] == -1 or i == (len(df1)-1)):
                # Cambio de Buy a Sell
                result = ((df1.loc[i,'Close'] - open_price) / open_price)*bet_size
                trades = trades.append({'Opening_Price':open_price,'Closing_Price':df1.loc[i,'Close'],'Return':result,'Type':'Long','Bet Size':bet_size}, ignore_index=True)
                open_price = df1.loc[i,'Close']
                trade_count += 1
                long_count += 1
                
            elif position == -1 and (df1.loc[i,'Buy_or_Sell'] == 1 or i == (len(df1)-1)):
                # Cambio de Sell a Buy
                result = ((open_price - df1.loc[i,'Close']) / open_price)*bet_size
                trades = trades.append({'Opening_Price':open_price,'Closing_Price':df1.loc[i,'Close'],'Return':result,'Type':'Short','Bet Size':bet_size}, ignore_index=True)
                open_price = df1.loc[i,'Close']
                trade_count += 1
                
                
            position = df1.loc[i,'Buy_or_Sell']
            bet_size = df1.loc[i,'Bet_Size']
        
        # print('*********** Trades ejecutados: **************')
        # print('*********************************************')
        # for i in range(len(trades)):
        #     print('Trade {}, tipo: {}'.format(i,trades.iloc[i,3]))
        #     print('Abrio al precio de $ {:.2f} y cerro en $ {:.2f}, con un size de {:.2f}'.format(trades.iloc[i,0],trades.iloc[i,1],trades.iloc[i,4]))
        #     print('Retorno: {:.2%}'.format(trades.iloc[i,2]))
        #     print('*********************************************')
        
        print('Portfolio result: {:.2%}'.format(trades['Return'].sum()))
        print('Trade quantity: {}'.format(trade_count))
        print('Ratio of Longs: {:.2%}'.format(long_count/trade_count))
        print('Sharpe Ratio: {:.3f}'.format((trades['Return'].sum()-risk_free)/trades['Return'].std()))
        print(trades['Return'].sum(),trades['Return'].std())
        return (trades['Return'].sum(),((trades['Return'].sum()-risk_free)/trades['Return'].std()))
                
    else:
        print('Modo incorrecto!')
        return 0

def cross_validate_backtest(df,n_folds,rf_parameters,r_free):
    fold_df = generate_k_folds_with_embargo(df,n_folds)
    backtest_results = pd.DataFrame(columns=['Fold','Buy and Hold - Return','Signalling - Return','Signalling - SharpeRatio',
                                             'Signal & Size - Return','Signal & Size - SharpeRatio'])
    for fold in range(n_folds):
        model=RandomForestClassifier(
        n_estimators=rf_parameters[0],
        max_depth=rf_parameters[1],
        min_samples_split=rf_parameters[2],
        min_samples_leaf=rf_parameters[3],
        max_features=rf_parameters[4],
        min_impurity_decrease=rf_parameters[5],
        min_weight_fraction_leaf=rf_parameters[6])
        
        df_test = df.loc[df.index.isin(fold_df.loc[fold,'vl_index'])]
        y_test = df_test.iloc[:,-1]
        x_test = df_test.iloc[:,:-1]
        
        df_train = df.loc[df.index.isin(fold_df.loc[fold,'tr_index'])]
        y_train = df_train.iloc[:,-1]
        x_train = df_train.iloc[:,:-1]
        
        model_weights = final_weight(x_train,'Close',0)
        
        x_train = x_train.iloc[:-1]
        y_train = y_train.iloc[:-1]
        
        rf = model.fit(x_train, y_train, sample_weight=model_weights)
        
        y_pred = rf.predict(x_test)
        y_pred_rf = rf.predict_proba(x_test)[:, 1]
        
        backtest_df = x_test
        backtest_df['Bet_Size'] = normalize_prob(y_pred_rf)
        backtest_df = backtest_df.rename(columns={'Signal':'Buy_or_Sell'})
        result_hold = back_test(backtest_df,mode='Simple')
        result_signal = back_test(backtest_df,mode='Signal',risk_free=r_free[fold])
        result_size = back_test(backtest_df,mode='BetS',risk_free=r_free[fold])
        backtest_results = backtest_results.append({'Fold':fold,'Buy and Hold - Return':result_hold,
                                                    'Signalling - Return':result_signal[0],'Signalling - SharpeRatio':result_signal[1],
                                                    'Signal & Size - Return':result_size[0],'Signal & Size - SharpeRatio':result_size[1]},
                                                   ignore_index=True)
    return backtest_results
    
    

## EXECUTION

os.chdir(r'F:\ArchivoNahuel\Estudio\Maestría - MIM+Analytics\Tesis')
etf_dataset = YC_Analysis_V3.main('TreasuryGov_data.txt')
etf_dataset = etf_dataset.drop(['10Y-2Y Real Today','10Y-2Y NS Today','10Y-2Y Forecast'],axis=1)

# Plot important variables for descriptive analytics.
etf_dataset.info()
plot_volume_and_price(etf_dataset)

# Sample into volume bars and remove null signals.
etf_dataset_final = etf_dataset
# etf_dataset_final = filter_volume_bar_df(etf_dataset_final,'Volume',10)
etf_dataset_final = etf_dataset_final[etf_dataset_final.Signal != '']

etf_dataset_final['Close_1d_diff'] = etf_dataset_final['Close'] - etf_dataset_final['Close'].shift(1)
etf_dataset_final['Close_2d_diff'] = etf_dataset_final['Close'] - etf_dataset_final['Close'].shift(2)
etf_dataset_final['Close_3d_diff'] = etf_dataset_final['Close'] - etf_dataset_final['Close'].shift(3)

etf_dataset_final = meta_labeling(etf_dataset_final, 'Signal')

etf_dataset_final = etf_dataset_final.iloc[3:,:]
etf_dataset_final = etf_dataset_final.iloc[:-1,:]
etf_dataset_final = etf_dataset_final.astype({'Meta_Label':'int64'})

#Search best hyperparameters for the model
results_bt = evaluate_best_parameters_rf(etf_dataset_final.iloc[int(len(etf_dataset_final)*0.7):],
              n_folds = 4, n_est = [500],m_dep=[20,30,40],
              min_s_spl=[4,8,15],min_s_l=[5,10,15],max_f=[4,8],min_i=[0.,0.1,0.25],min_w=[0.,0.1,0.25])

#Proportions
plt.figure(5)
plot_signal_proportion(['Incorrect decisions','Correct decisions'],
                       [(etf_dataset_final.groupby('Meta_Label').count() / etf_dataset_final.Meta_Label.count()).iloc[:,0][0],
                       (etf_dataset_final.groupby('Meta_Label').count() / etf_dataset_final.Meta_Label.count()).iloc[:,0][1]])


# Split dataset and compute weights based on both return and time attribution

y_test = etf_dataset_final.iloc[int(len(etf_dataset_final)*0.7):,-1]
x_test = etf_dataset_final.iloc[int(len(etf_dataset_final)*0.7):,:-1]
y_train = etf_dataset_final.iloc[:int(len(etf_dataset_final)*0.7),-1]
x_train = etf_dataset_final.iloc[:int(len(etf_dataset_final)*0.7),:-1]
model_weights = final_weight(x_train,'Close',0)
x_train = x_train.iloc[:-1]
y_train = y_train.iloc[:-1]
# x_test = x_test.iloc[:-1]
# y_test = y_test.iloc[:-1]

y_train = y_train.astype({'Meta_Label':'int64'})
y_test = y_test.astype({'Meta_Label':'int64'})

param_list = [1000,8,40,20,5,0.,0.]

# Test model with best parameters 1000 / 5 / 40 / 10 / 5 / 0. / 0.
clf2=RandomForestClassifier(
    n_estimators=param_list[0],
    max_depth=param_list[1],
    min_samples_split=param_list[2],
    min_samples_leaf=param_list[3],
    max_features=param_list[4],
    min_impurity_decrease=param_list[5],
    min_weight_fraction_leaf=param_list[6])
# clf2=BaggingClassifier(base_estimator=clf2,n_estimators=1000,
# max_features=1.)
rf = clf2.fit(x_train, y_train, sample_weight=model_weights)
# rf = clf2.fit(x_train, y_train)

print('{:.2%} of Labels (0)'.format((etf_dataset_final.groupby('Meta_Label').count() / etf_dataset_final.Meta_Label.count()).iloc[:,0][0]))
print('{:.2%} of Labels (1)'.format((etf_dataset_final.groupby('Meta_Label').count() / etf_dataset_final.Meta_Label.count()).iloc[:,0][1]))


# The random forest model by itself
y_pred_rf = rf.predict_proba(x_test)[:, 1]
y_pred = rf.predict(x_test)
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)
print('F1 Score: {:.2f}'.format(f1_score(y_test, y_pred, average='micro')))
print(classification_report(y_test, y_pred))

# plt.figure(6)
# ROC_Curve(fpr_rf,tpr_rf)

# plt.figure(7)
# Conf_Matrix(y_test,y_pred)

#Backtest - cross validation on training data.

results = cross_validate_backtest(etf_dataset_final.iloc[:int(len(etf_dataset_final)*0.7),:],4,param_list,[0.0028,0.0018,0.006,0.0024])

#Backtest - test data.

print('Evaluating on test data')

backtest_df = x_test.copy()
backtest_df['Bet_Size'] = normalize_prob(y_pred_rf)
backtest_df = backtest_df.rename(columns={'Signal':'Buy_or_Sell'})

trades_hold = back_test(backtest_df,mode='Simple')
print('---------------------------')
trades_signal = back_test(backtest_df,mode='Signal',risk_free=0.0143)
print('---------------------------')
trades_size = back_test(backtest_df,mode='BetS',risk_free=0.0143)
