## IMPORTING LIBRARIES

import numpy as np
import pandas as pd
import datetime
import matplotlib.pyplot as plt
import math
import yfinance as yf
from pandas_datareader import data as pdr
from statsmodels.tsa.arima_model import ARIMA
from sklearn.metrics import mean_squared_error
import time
import quandl
import requests
from pandas.io.json import json_normalize

## LOADING & INITIAL ANALYSIS ------------------------------------------------------------------------------

def load_and_prepare(txtfile):
    
    data = pd.read_csv(txtfile, sep="\t",header=0)
    
    data['Date'] = pd.to_datetime(data['Date'])
    data['Status'] = 'N'
    
    for i in range(len(data)):
        if data.iloc[i,3] == 'N/A ' or data.iloc[i,6] == 'N/A ' or data.iloc[i,9] == 'N/A ':
            data.iloc[i,13] = 'Y'
        
    data = data[data.Status == 'N']
    data = data.drop('Status',axis=1)
    data = data.replace('N/A ', np.nan)
    
    data = data.astype({'3 mo':'float64'})
    data = data.astype({'1 mo':'float64'})
    data = data.astype({'2 mo':'float64'})
    data = data.astype({'20 yr':'float64'})
    
    data = data.drop(columns=['1 yr','2 yr','3 yr','5 yr','7 yr','10 yr','20 yr','30 yr'],axis=1)
    
    data = data.set_index('Date',drop=False)

    zeroc_data = quandl.get("FED/SVENY", authtoken="uGUcfTxeoAzErLQiPxjF")
    out_data = data.merge(zeroc_data,left_index=True,right_index=True)

    for column in out_data.columns.values.tolist():
        if column[:5] == 'SVENY':
            out_data.rename(columns={column:(str(int(column[5:])) + ' yr')}, inplace=True)
    
    #Long-term factor:
    out_data['Level'] = out_data['10 yr']
    
    #Short-term factor:
    out_data['Slope'] = out_data['10 yr']-out_data['3 mo']
    
    #Medium-term factor:
    out_data['Curvature'] = 2*out_data['2 yr']-(out_data['10 yr']+out_data['3 mo'])

    return out_data


def plot_components(data):
    
    plt.subplot(3,1,1)
    plt.plot(data['Date'],data['Level'],'g')
    plt.title('Level evolution over time')
    plt.xticks([])
    
    plt.subplot(3,1,2)
    plt.plot(data['Date'],data['Slope'],'c')
    plt.title('Slope evolution over time')
    plt.xticks([])

    plt.subplot(3,1,3)
    plt.plot(data['Date'],data['Curvature'],'b')
    plt.title('Curvature evolution over time')


def generate_curve_source(data,date_string):
    
    data = data.loc[date_string]
    yield_rates = []
    for index in data.index:
        if index not in {'Date','Slope','Level','Curvature'}:
            yield_rates.append(data[index])
    maturity_in_months = [1,2,3,6,12,24,36,48,60,72,84,96,108,120,132,144,156,168,180,192,204,216,228,240,252,264,276,288,300,312,324,336,348,360]
    curve_data = pd.DataFrame(data={'Maturity (Months)':maturity_in_months,('yc_real_'+date_string):yield_rates})
    return curve_data

def generate_NS_curve(data,date_string):
    data = data.loc[date_string]
    level = data['Level']
    slope = data['Slope']
    curvature = data['Curvature']
    maturity_in_months = [1,2,3,6,12,24,36,48,60,72,84,96,108,120,132,144,156,168,180,192,204,216,228,240,252,264,276,288,300,312,324,336,348,360]
    data_NS = pd.DataFrame({'Maturity (Months)':maturity_in_months})        
    l = 0.0609 #30 months, average between 2 years and 3 years.
    data_NS[('yc_NS_'+date_string)] = ''
    
    for i in range(len(maturity_in_months)):
        t = maturity_in_months[i]
        data_NS.iloc[i,1] = level + slope * (-(1-math.exp(-t*l))/(t*l)) + curvature * ((((1-math.exp(-t*l))/(t*l))-math.exp(-t*l)))
    return data_NS    

def generate_NS_curve_index(data,need_filter=False,index=0):
    if need_filter:
        data = data.loc[index]
    level = data[0]
    slope = data[1]
    curvature = data[2]
    maturity_in_months = [1,2,3,6,12,24,36,60,84,120,240,360]
    data_NS = pd.DataFrame({'Maturity (Months)':maturity_in_months})        
    l = 0.0609 #30 months, average between 2 years and 3 years.
    data_NS[('yc_NS_'+str(index))] = ''
    # data_NS['Level weight'] = ''   
    # data_NS['Slope weight'] = ''   
    # data_NS['Curvature weight'] = ''   
    
    for i in range(len(maturity_in_months)):
        t = maturity_in_months[i]
        data_NS.iloc[i,1] = level + slope * (-(1-math.exp(-t*l))/(t*l)) + curvature * ((((1-math.exp(-t*l))/(t*l))-math.exp(-t*l)))
    return data_NS    
   
def compare_two_curves(curve_data1,label1,curve_data2,label2):
    curve_data1 = curve_data1.iloc[0:14,:]
    curve_data2 = curve_data2.iloc[0:14,:]
    fig, ax = plt.subplots()
    ax.plot(curve_data1.iloc[:,0],curve_data1.iloc[:,1], '-b', label=label1)
    ax.plot(curve_data2.iloc[:,0],curve_data2.iloc[:,1], '--r', label=label2)
    ax.legend()
    plt.show()
    

## MODELING CURVE ------------------------------------------------------------------------------------------       

def predict_daily(data,p,d,q,index_predict):
    
    data = data.dropna()
    
    start_value = data.loc[index_predict-1]
    
    real_value = data.loc[index_predict]
    
    train_data = data.loc[:index_predict-1]
    
    mod = ARIMA(train_data, order = (p,d,q))
    mod_fit = mod.fit()
    # print('The lag value chose is: %s' % mod_fit.k_ar)
    # print('The coefficients of the model are:\n %s' % mod_fit.params)
    
    pred_value = mod_fit.forecast()
    
    # print('Real value:',real_value)
    # print('Predicted value:',pred_value[0])
    
    # print('Starting point:',start_value)    
    # print('Predicted:',pred_value[0][0])
    # print('Actual:',real_value)
    
    if pred_value[0][0] < start_value:
        pred_direction = 'Decrease'
    else:
        pred_direction = 'Increase'
        
    if real_value < start_value:
        real_direction = 'Decrease'
    else:
        real_direction = 'Increase'
    
    return [start_value, pred_value[0][0], pred_direction, real_value, real_direction]

    
def model_test_extended_daily(data,max_p,d,max_q,test_obs):
    test_results = pd.DataFrame(columns=['AR','MA','RMSE','DIRECTION_ACC'])
    for p in range(1,max_p+1):
        for q in range(0,max_q+1):
            model_results_compiled = pd.DataFrame(columns=['SV','PV','PD','RV','RD','DIRECTION_PRED'])
            print('Processing ARMA model with AR order p = {}, and MA order q = {}'.format(p,q))
            exceptions = 0
            for i in range((len(data)-test_obs),len(data)):
                # print(model_results_compiled)
                try:
                    mod_results = predict_daily(data,p,d,q,i)
                    model_results_compiled = model_results_compiled.append({'SV':mod_results[0],'PV':mod_results[1],'PD':mod_results[2],
                                                                            'RV':mod_results[3],'RD':mod_results[4],
                                                                            'DIRECTION_PRED':(mod_results[2]==mod_results[4])},ignore_index=True)
                    
                except Exception:
                    print('Exception!')
                    exceptions += 1
                    if exceptions == 10:
                        break;
                print('Progress: {:.2%}'.format((i-(len(data)-test_obs))/test_obs))
            
            if exceptions < 10:
                matches = model_results_compiled.loc[model_results_compiled['DIRECTION_PRED'] == True, 'DIRECTION_PRED'].count()
                records = model_results_compiled['DIRECTION_PRED'].count()
                test_results = test_results.append({'AR':p,'MA':q,
                                                    'RMSE':math.sqrt(mean_squared_error(model_results_compiled['RV'],model_results_compiled['PV'])),
                                                    'DIRECTION_ACC':(matches/records)},
                                                   ignore_index=True)     
            else:
                test_results = test_results.append({'AR':p,'MA':q,
                                                    'RMSE':np.nan,
                                                    'DIRECTION_ACC': np.nan},
                                                   ignore_index=True)  
    return test_results

def model_test_daily(data,p,d,q,test_obs):
    test_results = pd.DataFrame(columns=['AR','MA','RMSE','DIRECTION_ACC'])
    model_results_compiled = pd.DataFrame(columns=['SV','PV','PD','RV','RD','DIRECTION_PRED'])
    print('Processing ARMA model with AR order p = {}, and MA order q = {}'.format(p,q))
    exceptions = 0
    for i in range((len(data)-test_obs),len(data)):
        # print(model_results_compiled)
        try:
            mod_results = predict_daily(data,p,d,q,i)
            model_results_compiled = model_results_compiled.append({'SV':mod_results[0],'PV':mod_results[1],'PD':mod_results[2],
                                                                    'RV':mod_results[3],'RD':mod_results[4],
                                                                    'DIRECTION_PRED':(mod_results[2]==mod_results[4])},ignore_index=True)
            
        except Exception:
            print('Exception!')
            exceptions += 1
            if exceptions == 10:
                break;
        print('Progress: {:.2%}'.format((i-(len(data)-test_obs))/test_obs))
    
    if exceptions < 10:
        matches = model_results_compiled.loc[model_results_compiled['DIRECTION_PRED'] == True, 'DIRECTION_PRED'].count()
        records = model_results_compiled['DIRECTION_PRED'].count()
        test_results = test_results.append({'AR':p,'MA':q,
                                            'RMSE':math.sqrt(mean_squared_error(model_results_compiled['RV'],model_results_compiled['PV'])),
                                            'DIRECTION_ACC':(matches/records)},
                                           ignore_index=True)     
    else:
        test_results = test_results.append({'AR':p,'MA':q,
                                            'RMSE':np.nan,
                                            'DIRECTION_ACC': np.nan},
                                           ignore_index=True)  
    return test_results

## CONFIGURATION FOR ETF DATASET - LABELING ----------------------------------------------------------------

def load_etf(ticker,mode):
    if mode == 'yahoo':
        # check = yf.Ticker(ticker)
        stocks = [ticker]
        start = datetime.datetime(2000,11,30)
        end = datetime.datetime(2020,1,4)
        
        yf.pdr_override()
        
        df_etf = pdr.get_data_yahoo(stocks, start=start, end=end)
        
    if mode == 'API':
        headers = {
            'Content-Type': 'application/json'
        }
        requestResponse = requests.get("https://api.tiingo.com/tiingo/daily/stpp/prices?startDate=2010-01-02&token=d4ccd8a58b8cac90dbdf5b6b23f682d58b1e2d5b", headers=headers)
        df = pd.DataFrame.from_dict(json_normalize(requestResponse.json()), orient='columns')
        df = df.drop(['adjHigh','adjLow','adjOpen','adjVolume','divCash','splitFactor'],axis=1)
        df.columns = df.columns.str.capitalize()
        df = df.rename(columns={'Adjclose':'Adj Close'})
        df['Date'] = pd.to_datetime(df['Date'], format="%Y-%m-%dT%H:%M:%S.%fZ")
        df = df.set_index('Date')
        df = df.loc[:'2020-04-01']
        df_etf = df.reindex(columns = ['Open','High','Low','Close','Adj Close','Volume'])
    
    return df_etf   

def forecast_daily(data,p,d,q,index_predict):
    
    data = data.dropna()
    
    train_data = data.loc[:index_predict-1]
    
    mod = ARIMA(train_data, order = (p,d,q))
    mod_fit = mod.fit()
    
    pred_value = mod_fit.forecast()
    
    return pred_value[0][0]

def generate_and_process_predictions_daily(data,start_index):
    predictions = pd.DataFrame(columns=['Index','Level','Slope','Curvature'])
    p_level = np.nan
    p_slope = np.nan
    p_curvature = np.nan
    for i in range(start_index,len(data)+1):                        
        p_level = np.nan
        p_slope = np.nan
        p_curvature = np.nan
        
        print('Processing for index {}. Ending Index is {}'.format(i,len(data)))
        
        try:
            p_level = forecast_daily(data['Level'],1,1,0,i)
        except Exception:
            continue

        try:
            p_slope = forecast_daily(data['Slope'],1,1,0,i)
        except Exception:
            continue

        try:
            p_curvature = forecast_daily(data['Curvature'],1,1,0,i)
        except Exception:
            continue                
        
        predictions = predictions.append({'Index':i,
                                          'Level':p_level,
                                          'Slope':p_slope,
                                          'Curvature':p_curvature},ignore_index=True)
                
    return predictions      

# We extract information, to complement the ETF dataset, required to exploit the curve signal from the primary model.
# This ETF follows the performance of Barclays INDEX for the treasuries 2Y / 10Y (difference)
# If steepning occurs, the index(and ETF) level will raise, otherwise, if the yield curve flattens, the index level will decrease.
def process_etf_dataset_daily(etf_data,yc_real,yc_daily,yc_pred):
    df_new = etf_data
    df_new['10Y-2Y Real Today'] = ''
    df_new['10Y-2Y NS Today'] = ''
    df_new['10Y-2Y Forecast'] = ''
    df_new['Signal'] = ''
    
    proc_daily = yc_daily.copy()
    proc_daily = proc_daily.loc['2010-08-10':]
    proc_daily['10Y-2Y NS Today'] = ''
    for i in range(len(proc_daily)):        
        try:
            curve = generate_NS_curve_index(proc_daily.iloc[i,:])
            proc_daily.iloc[i,3] = curve.loc[9][1] - curve.loc[5][1]
        except Exception:
            continue  
    
    proc_pred = yc_pred.copy()
    proc_pred['10Y-2Y Forecast'] = ''
    for i in range(len(proc_pred)):        
        try:
            curve = generate_NS_curve_index(proc_pred.iloc[i,:])
            proc_pred.iloc[i,3] = curve.loc[9][1] - curve.loc[5][1]
        except Exception:
            continue  
        
    df_new['10Y-2Y Real Today'] = yc_real['10 yr'] - yc_real['2 yr']
    df_new['10Y-2Y NS Today'] = proc_daily['10Y-2Y NS Today']
    df_new['10Y-2Y Forecast'] = proc_pred['10Y-2Y Forecast']
    del(i)
    for i in range(len(etf_data)):
        if df_new.iloc[i,7] < df_new.iloc[i,8]:
            df_new.iloc[i,9] = 1
        elif df_new.iloc[i,7] > df_new.iloc[i,8]:
            df_new.iloc[i,9] = -1
    return df_new   

def signal_accuracy(data):
    correct_count = 0
    stay = 0
    for i in range(0,len(data)-1):
        if data.iloc[i,:]['10Y-2Y Real Today'] > data.iloc[i+1,:]['10Y-2Y Real Today'] and data.iloc[i,:]['Signal'] == -1:
            correct_count += 1
        elif data.iloc[i,:]['10Y-2Y Real Today'] < data.iloc[i+1,:]['10Y-2Y Real Today'] and data.iloc[i,:]['Signal'] == 1:
            correct_count += 1
        elif data.iloc[i,:]['10Y-2Y Real Today'] == data.iloc[i+1,:]['10Y-2Y Real Today']:
            stay += 1
    print('Signal accuracy = {:.2%}'.format(correct_count/(len(data)-1)))    
    print('Stay situation propotion = {:.2%}'.format(stay/(len(data)-1)))    
    print('Signal accuracy including Stay = {:.2%}'.format((correct_count+stay)/(len(data)-1)))


# Main Code            

def main(txtfile):
    s = time.time()    
    yc_dataset = load_and_prepare(txtfile)
    plt.figure(1)
    plot_components(yc_dataset)
    plt.figure(2)
    compare_two_curves(generate_NS_curve(yc_dataset,'2016-02-04'),'2016 Feb 4th',generate_NS_curve(yc_dataset,'2016-08-01'),'2016 Aug 1st')
    
    plt.figure(3)
    compare_two_curves(generate_curve_source(yc_dataset,'2016-02-04'),'2016 Feb 4th',generate_curve_source(yc_dataset,'2016-08-01'),'2016 Aug 1st')
    
    daily_data = yc_dataset[['Level','Slope','Curvature']]
    daily_data = daily_data.reset_index()
    # daily_data = daily_data.set_index('Date')
    
    # # #Test Section!
    # # #AR(1) is best
    # # test_level = model_test_extended_daily(daily_data['Level'],1,1,0,100)
    # # slope_level = model_test_extended_daily(daily_data['Slope'],1,1,0,100) # 9 0
    # # curvature_level = model_test_extended_daily(daily_data['Curvature'],1,1,0,1500)    
    yc_daily = daily_data.set_index('Date')
    
    # #2010-08-10 starting point of etf dataset, index = 5153
    yc_d_predictions = generate_and_process_predictions_daily(daily_data,5153)
    yc_d_predictions['Index'] = yc_d_predictions['Index']-1
    yc_d_predictions = yc_d_predictions.astype({'Index':'int64'})
    yc_d_predictions = yc_d_predictions.set_index('Index')
    yc_d_predictions['Date'] = daily_data['Date']
    yc_d_predictions = yc_d_predictions.set_index('Date')
    
    etf_dataset = process_etf_dataset_daily(load_etf('STPP',mode='API'),yc_dataset,yc_daily,yc_d_predictions)
    
    signal_accuracy(etf_dataset)
    
    # compare_two_curves(generate_NS_curve_index(yc_d_predictions.iloc[1,:]),'Pred',generate_NS_curve_index(daily_data[['Level','Slope','Curvature']],need_filter=True,index=7401),'Real')
    
    print('Time elapsed: {} seconds'.format(round(time.time()-s,2)))  
   
    return etf_dataset
    

if __name__ == '__main__':
    yc_dataset = main('TreasuryGov_data.txt')